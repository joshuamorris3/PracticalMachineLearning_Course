
<!DOCTYPE html><html><head><script type="text/javascript">(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){this.t[a]=[void 0!=b?b:(new Date).getTime(),c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(d){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_","_wtsrt",
d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})()
</script>
<script type="text/javascript">var KX_timer = new window.jstiming.Timer(); KX_timer.name = 'published';</script><title>Assignment Final</title><link rel="shortcut icon" href="https://ssl.gstatic.com/docs/documents/images/kix-favicon6.ico"><style type="text/css">
      body {
        font-family: arial, sans, sans-serif;
        margin: 0;
      }

      iframe {
        border: 0;
        frameborder: 0;
        height: 100%;
        width: 100%;
      }

      #header, #footer {
        background: #f0f0f0;
        padding: 10px 10px;
      }

      #header {
        border-bottom: 1px #ccc solid;
      }

      #footer {
        border-top: 1px #ccc solid;
        border-bottom: 1px #ccc solid;
        font-size: 13;
      }

      #contents {
        margin: 6px;
      }

      .dash {
        padding: 0 6px;
      }
    </style></head><body><div id="header">Assignment Final</div><div id="contents"><style type="text/css">.lst-kix_m2hsvesez691-3>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-3,decimal) ". "}.lst-kix_m2hsvesez691-2>li{counter-increment:lst-ctn-kix_m2hsvesez691-2}.lst-kix_3kc93yro6ork-1>li{counter-increment:lst-ctn-kix_3kc93yro6ork-1}.lst-kix_m2hsvesez691-4>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-4,lower-latin) ". "}ol.lst-kix_3kc93yro6ork-8.start{counter-reset:lst-ctn-kix_3kc93yro6ork-8 0}.lst-kix_3kc93yro6ork-3>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-3,decimal) ". "}.lst-kix_aoojs3l1x5cn-8>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-8}.lst-kix_aoojs3l1x5cn-1>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-1}ol.lst-kix_aoojs3l1x5cn-0{list-style-type:none}.lst-kix_m2hsvesez691-7>li{counter-increment:lst-ctn-kix_m2hsvesez691-7}.lst-kix_aoojs3l1x5cn-2>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-2,lower-roman) ". "}ol.lst-kix_aoojs3l1x5cn-8{list-style-type:none}ol.lst-kix_aoojs3l1x5cn-7{list-style-type:none}ol.lst-kix_aoojs3l1x5cn-6{list-style-type:none}ol.lst-kix_aoojs3l1x5cn-5{list-style-type:none}.lst-kix_3kc93yro6ork-0>li{counter-increment:lst-ctn-kix_3kc93yro6ork-0}.lst-kix_fbuae3vzvoqx-6>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-6}ol.lst-kix_aoojs3l1x5cn-4{list-style-type:none}ol.lst-kix_aoojs3l1x5cn-3{list-style-type:none}ol.lst-kix_aoojs3l1x5cn-2{list-style-type:none}ol.lst-kix_aoojs3l1x5cn-1{list-style-type:none}.lst-kix_aoojs3l1x5cn-8>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-8,lower-roman) ". "}ol.lst-kix_aoojs3l1x5cn-8.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-8 0}ol.lst-kix_fbuae3vzvoqx-8{list-style-type:none}ol.lst-kix_fbuae3vzvoqx-7{list-style-type:none}ol.lst-kix_fbuae3vzvoqx-6{list-style-type:none}.lst-kix_3kc93yro6ork-8>li{counter-increment:lst-ctn-kix_3kc93yro6ork-8}ol.lst-kix_fbuae3vzvoqx-5{list-style-type:none}ol.lst-kix_fbuae3vzvoqx-8.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-8 0}ol.lst-kix_aoojs3l1x5cn-0.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-0 0}.lst-kix_m2hsvesez691-8>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-8,lower-roman) ". "}ol.lst-kix_fbuae3vzvoqx-0{list-style-type:none}.lst-kix_m2hsvesez691-1>li{counter-increment:lst-ctn-kix_m2hsvesez691-1}ol.lst-kix_fbuae3vzvoqx-4{list-style-type:none}ol.lst-kix_fbuae3vzvoqx-3{list-style-type:none}ol.lst-kix_fbuae3vzvoqx-2{list-style-type:none}.lst-kix_fbuae3vzvoqx-5>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-5,lower-roman) ". "}ol.lst-kix_fbuae3vzvoqx-1{list-style-type:none}.lst-kix_aoojs3l1x5cn-5>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-5,lower-roman) ". "}ol.lst-kix_3kc93yro6ork-1.start{counter-reset:lst-ctn-kix_3kc93yro6ork-1 0}.lst-kix_m2hsvesez691-7>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-7,lower-latin) ". "}.lst-kix_aoojs3l1x5cn-4>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-4}ol.lst-kix_3kc93yro6ork-6.start{counter-reset:lst-ctn-kix_3kc93yro6ork-6 0}.lst-kix_m2hsvesez691-6>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-6,decimal) ". "}.lst-kix_fbuae3vzvoqx-0>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-0,decimal) ". "}ol.lst-kix_aoojs3l1x5cn-4.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-4 0}.lst-kix_fbuae3vzvoqx-7>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-7}.lst-kix_fbuae3vzvoqx-3>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-3}.lst-kix_fbuae3vzvoqx-2>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-2,lower-roman) ". "}.lst-kix_fbuae3vzvoqx-4>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-4,lower-latin) ". "}ol.lst-kix_3kc93yro6ork-5.start{counter-reset:lst-ctn-kix_3kc93yro6ork-5 0}.lst-kix_fbuae3vzvoqx-4>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-4}ol.lst-kix_m2hsvesez691-4.start{counter-reset:lst-ctn-kix_m2hsvesez691-4 0}.lst-kix_aoojs3l1x5cn-6>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-6,decimal) ". "}.lst-kix_aoojs3l1x5cn-6>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-6}ol.lst-kix_3kc93yro6ork-2.start{counter-reset:lst-ctn-kix_3kc93yro6ork-2 0}ol.lst-kix_fbuae3vzvoqx-4.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-4 0}ol.lst-kix_fbuae3vzvoqx-3.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-3 0}.lst-kix_3kc93yro6ork-7>li{counter-increment:lst-ctn-kix_3kc93yro6ork-7}.lst-kix_fbuae3vzvoqx-2>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-2}.lst-kix_fbuae3vzvoqx-3>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-3,decimal) ". "}ol.lst-kix_m2hsvesez691-3.start{counter-reset:lst-ctn-kix_m2hsvesez691-3 0}.lst-kix_3kc93yro6ork-1>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-1,lower-latin) ". "}.lst-kix_aoojs3l1x5cn-3>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-3}.lst-kix_aoojs3l1x5cn-0>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-0,decimal) ". "}.lst-kix_3kc93yro6ork-5>li{counter-increment:lst-ctn-kix_3kc93yro6ork-5}.lst-kix_aoojs3l1x5cn-3>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-3,decimal) ". "}.lst-kix_3kc93yro6ork-8>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-8,lower-roman) ". "}.lst-kix_aoojs3l1x5cn-2>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-2}ol.lst-kix_m2hsvesez691-7.start{counter-reset:lst-ctn-kix_m2hsvesez691-7 0}.lst-kix_m2hsvesez691-2>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-2,lower-roman) ". "}.lst-kix_m2hsvesez691-5>li{counter-increment:lst-ctn-kix_m2hsvesez691-5}.lst-kix_3kc93yro6ork-2>li{counter-increment:lst-ctn-kix_3kc93yro6ork-2}ol.lst-kix_fbuae3vzvoqx-2.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-2 0}.lst-kix_aoojs3l1x5cn-7>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-7}ol.lst-kix_3kc93yro6ork-3.start{counter-reset:lst-ctn-kix_3kc93yro6ork-3 0}ol.lst-kix_3kc93yro6ork-4.start{counter-reset:lst-ctn-kix_3kc93yro6ork-4 0}.lst-kix_m2hsvesez691-6>li{counter-increment:lst-ctn-kix_m2hsvesez691-6}ol.lst-kix_3kc93yro6ork-7.start{counter-reset:lst-ctn-kix_3kc93yro6ork-7 0}.lst-kix_m2hsvesez691-4>li{counter-increment:lst-ctn-kix_m2hsvesez691-4}.lst-kix_aoojs3l1x5cn-7>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-7,lower-latin) ". "}.lst-kix_3kc93yro6ork-5>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-5,lower-roman) ". "}.lst-kix_3kc93yro6ork-0>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-0,decimal) ". "}.lst-kix_fbuae3vzvoqx-5>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-5}.lst-kix_3kc93yro6ork-2>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-2,lower-roman) ". "}ol.lst-kix_m2hsvesez691-5.start{counter-reset:lst-ctn-kix_m2hsvesez691-5 0}.lst-kix_3kc93yro6ork-6>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-6,decimal) ". "}ol.lst-kix_aoojs3l1x5cn-2.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-2 0}ol.lst-kix_fbuae3vzvoqx-1.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-1 0}.lst-kix_3kc93yro6ork-4>li{counter-increment:lst-ctn-kix_3kc93yro6ork-4}.lst-kix_m2hsvesez691-3>li{counter-increment:lst-ctn-kix_m2hsvesez691-3}.lst-kix_fbuae3vzvoqx-0>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-0}.lst-kix_fbuae3vzvoqx-8>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-8}ol.lst-kix_aoojs3l1x5cn-5.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-5 0}.lst-kix_fbuae3vzvoqx-6>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-6,decimal) ". "}ol.lst-kix_3kc93yro6ork-7{list-style-type:none}ol.lst-kix_3kc93yro6ork-6{list-style-type:none}ol.lst-kix_aoojs3l1x5cn-6.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-6 0}ol.lst-kix_3kc93yro6ork-5{list-style-type:none}ol.lst-kix_3kc93yro6ork-4{list-style-type:none}.lst-kix_3kc93yro6ork-6>li{counter-increment:lst-ctn-kix_3kc93yro6ork-6}ol.lst-kix_m2hsvesez691-1.start{counter-reset:lst-ctn-kix_m2hsvesez691-1 0}.lst-kix_aoojs3l1x5cn-1>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-1,lower-latin) ". "}.lst-kix_m2hsvesez691-1>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-1,lower-latin) ". "}ol.lst-kix_3kc93yro6ork-8{list-style-type:none}ol.lst-kix_m2hsvesez691-0.start{counter-reset:lst-ctn-kix_m2hsvesez691-0 0}.lst-kix_fbuae3vzvoqx-1>li{counter-increment:lst-ctn-kix_fbuae3vzvoqx-1}.lst-kix_3kc93yro6ork-4>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-4,lower-latin) ". "}ol.lst-kix_fbuae3vzvoqx-0.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-0 0}ol.lst-kix_aoojs3l1x5cn-7.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-7 0}.lst-kix_3kc93yro6ork-7>li:before{content:"" counter(lst-ctn-kix_3kc93yro6ork-7,lower-latin) ". "}.lst-kix_m2hsvesez691-8>li{counter-increment:lst-ctn-kix_m2hsvesez691-8}ol.lst-kix_fbuae3vzvoqx-6.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-6 0}.lst-kix_fbuae3vzvoqx-7>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-7,lower-latin) ". "}.lst-kix_fbuae3vzvoqx-1>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-1,lower-latin) ". "}ol.lst-kix_3kc93yro6ork-0{list-style-type:none}ol.lst-kix_3kc93yro6ork-1{list-style-type:none}.lst-kix_3kc93yro6ork-3>li{counter-increment:lst-ctn-kix_3kc93yro6ork-3}.lst-kix_m2hsvesez691-5>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-5,lower-roman) ". "}.lst-kix_m2hsvesez691-0>li:before{content:"" counter(lst-ctn-kix_m2hsvesez691-0,decimal) ". "}ol.lst-kix_3kc93yro6ork-2{list-style-type:none}ol.lst-kix_3kc93yro6ork-3{list-style-type:none}ol.lst-kix_m2hsvesez691-8.start{counter-reset:lst-ctn-kix_m2hsvesez691-8 0}ol.lst-kix_fbuae3vzvoqx-5.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-5 0}.lst-kix_aoojs3l1x5cn-5>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-5}ol.lst-kix_m2hsvesez691-8{list-style-type:none}.lst-kix_m2hsvesez691-0>li{counter-increment:lst-ctn-kix_m2hsvesez691-0}ol.lst-kix_m2hsvesez691-6{list-style-type:none}ol.lst-kix_m2hsvesez691-7{list-style-type:none}ol.lst-kix_m2hsvesez691-4{list-style-type:none}ol.lst-kix_m2hsvesez691-5{list-style-type:none}ol.lst-kix_m2hsvesez691-2{list-style-type:none}ol.lst-kix_m2hsvesez691-3{list-style-type:none}ol.lst-kix_m2hsvesez691-1{list-style-type:none}ol.lst-kix_m2hsvesez691-0{list-style-type:none}.lst-kix_aoojs3l1x5cn-0>li{counter-increment:lst-ctn-kix_aoojs3l1x5cn-0}ol.lst-kix_aoojs3l1x5cn-3.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-3 0}.lst-kix_aoojs3l1x5cn-4>li:before{content:"" counter(lst-ctn-kix_aoojs3l1x5cn-4,lower-latin) ". "}.lst-kix_fbuae3vzvoqx-8>li:before{content:"" counter(lst-ctn-kix_fbuae3vzvoqx-8,lower-roman) ". "}ol.lst-kix_3kc93yro6ork-0.start{counter-reset:lst-ctn-kix_3kc93yro6ork-0 0}ol.lst-kix_fbuae3vzvoqx-7.start{counter-reset:lst-ctn-kix_fbuae3vzvoqx-7 0}ol.lst-kix_m2hsvesez691-6.start{counter-reset:lst-ctn-kix_m2hsvesez691-6 0}ol.lst-kix_m2hsvesez691-2.start{counter-reset:lst-ctn-kix_m2hsvesez691-2 0}ol.lst-kix_aoojs3l1x5cn-1.start{counter-reset:lst-ctn-kix_aoojs3l1x5cn-1 0}ol{margin:0;padding:0}.c1{padding-left:0pt;widows:2;orphans:2;direction:ltr;margin-left:36pt}.c0{widows:2;orphans:2;text-align:center;direction:ltr}.c2{widows:2;orphans:2;height:11pt;direction:ltr}.c7{max-width:468pt;background-color:#ffffff;padding:72pt 72pt 72pt 72pt}.c3{widows:2;orphans:2;direction:ltr}.c5{font-size:13pt;font-family:"Trebuchet MS";font-weight:bold}.c8{margin:0;padding:0}.c9{color:#1155cc;text-decoration:underline}.c6{color:inherit;text-decoration:inherit}.c4{page-break-after:avoid}.title{widows:2;padding-top:0pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:21pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}.subtitle{widows:2;padding-top:0pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-style:italic;font-size:13pt;font-family:"Trebuchet MS";padding-bottom:10pt;page-break-after:avoid}li{color:#000000;font-size:11pt;font-family:"Arial"}p{color:#000000;font-size:11pt;margin:0;font-family:"Arial"}h1{widows:2;padding-top:10pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:16pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h2{widows:2;padding-top:10pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:13pt;font-family:"Trebuchet MS";font-weight:bold;padding-bottom:0pt;page-break-after:avoid}h3{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:12pt;font-family:"Trebuchet MS";font-weight:bold;padding-bottom:0pt;page-break-after:avoid}h4{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:11pt;text-decoration:underline;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h5{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:11pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h6{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-style:italic;font-size:11pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}</style><p class="c3 c4 title"><a name="h.ul83y59xv4wj"></a><span>Practical Machine Learning Course Project</span></p><h1 class="c3 c4"><a name="h.vu1exk6hq5z7"></a><span>Overview</span></h1><p class="c3"><span>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, we use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The goal of the project is to predict the manner in which they did the exercise.</span></p><p class="c2"><span></span></p><p class="c3"><span>The data for this project come from this source: </span><span class="c9"><a class="c6" href="http://www.google.com/url?q=http%3A%2F%2Fgroupware.les.inf.puc-rio.br%2Fhar&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGGaSH9yezy_c6Q0mBYf-wkov9nKA">http://groupware.les.inf.puc-rio.br/har</a></span><span>.</span></p><h1 class="c3 c4"><a name="h.op9mnq17kjhu"></a><span>Approach</span></h1><p class="c3"><span>Steps to create a model to predict the manner in which exercises are performed:</span></p><ol class="c8 lst-kix_m2hsvesez691-0 start" start="1"><li class="c1"><span>Load the training and test data</span></li><li class="c1"><span>Clean up both datasets</span></li><li class="c1"><span>Partition the training set into training and test data</span></li><li class="c1"><span>Set up the ability to use multiple CPU’s to speed up the model creation step</span></li><li class="c1"><span>Train a model using random forest (explanation why random forest below)</span></li><li class="c1"><span>Apply against test data set created from the original training set (step 3)</span></li><li class="c1"><span>Estimate Out of Sample Error</span></li><li class="c1"><span>Apply the model against the original test data with unknown outcomes to determine the manner in which each exercise was performed</span></li><li class="c1"><span>Write the outcomes to a file for upload for assessment</span></li></ol><h1 class="c3 c4"><a name="h.ahrgvg5cj7g8"></a><span>R Environment Setup</span></h1><p class="c3"><span>install.packages(“caret”,dependencies=TRUE)</span></p><p class="c3"><span>install.packages(“randomForest”,dependencies=TRUE)</span></p><p class="c3"><span>install.packages(“doParallel”,dependencies=TRUE)</span></p><p class="c3"><span>library(caret)</span></p><p class="c3"><span>library(randomForest)</span></p><p class="c3"><span>library(doParallel)</span></p><h1 class="c3 c4"><a name="h.3sfvpp25b3g6"></a><span>Loading and Cleaning the Datasets</span></h1><p class="c3"><span>I downloaded the datasets manually from the Assignment Writeup page, then proceeded to load and clean the data:</span></p><h2 class="c3 c4"><a name="h.a1qbm17e9tag"></a><span>Load and initial clean</span></h2><p class="c3"><span>Load both the training and testing data, cleaning up any NA, empty or divide by zero error strings using ‘na.strings’ option of read.csv.</span></p><p class="c2"><span></span></p><p class="c3"><span>pmlTraining = read.csv(&quot;../pml_course/pml-training.csv&quot;, na.strings = c(&quot;NA&quot;,&quot;&quot;,&quot;#DIV/0!&quot;))</span></p><p class="c3"><span>pmlTesting = read.csv(&quot;../pml_course/pml-testing.csv&quot;, na.strings = c(&quot;NA&quot;,&quot;&quot;,&quot;#DIV/0!&quot;))</span></p><p class="c2"><span></span></p><p class="c3"><span>This results in the following data sets:</span></p><p class="c2"><span></span></p><p class="c3"><span>&gt; dim(pmlTraining)</span></p><p class="c3"><span>[1] 19622   160</span></p><p class="c3"><span>&gt; dim(pmlTesting)</span></p><p class="c3"><span>[1]  20 160</span></p><p class="c2"><span></span></p><p class="c3"><span class="c5">Remove NA and Unnecessary Data</span></p><p class="c3"><span>The next step is to remove data not useful to in our training step, this includes incomplete data, columns with NA’s in this case, and columns we won’t be using to train the data, in this case columns 1 through 7 i.e. columns named X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, and num_window. We remove these as we need only focus in on the raw sensor data related to movement, and time related data is not important in this model since the movement, good or bad can happen at any time.</span></p><h3 class="c3 c4"><a name="h.fya5lkgw06t0"></a><span>Start with the training data</span></h3><p class="c3"><span>training &lt;- pmlTraining[,colSums(is.na(pmlTraining)) == 0][,-c(1:7)]</span></p><h3 class="c3 c4"><a name="h.g4o4mafl6lqm"></a><span>Match and remove the same columns from the test data</span></h3><p class="c3"><span>colUsed &lt;- colnames(pmlTraining[,colSums(is.na(pmlTraining)) == 0])[-(1:7)]<br>testingData &lt;- pmlTesting[colUsed[colUsed!=&#39;classe&#39;]]</span></p><p class="c2"><span></span></p><p class="c3"><span>This results in the following data that has just the outcome variable (in the training set only) and potential predictors:</span></p><p class="c2"><span></span></p><p class="c3"><span>&gt; dim(training)</span></p><p class="c3"><span>[1] 19622    53</span></p><p class="c3"><span>&gt; dim(testingData)</span></p><p class="c3"><span>[1] 20 52 # We have 52 because classe is not included, this is the outcome we are wanting to predict</span></p><h1 class="c3 c4"><a name="h.j516uqj43ky3"></a><span>Partition the training set into a training and test set</span></h1><p class="c3"><span>We partition on the classe variable, and in the case use a 75/25 split for training/test data</span></p><p class="c2"><span></span></p><p class="c3"><span>inTrain &lt;- createDataPartition(training$classe,p=0.75,list=FALSE)</span></p><p class="c3"><span>trainData &lt;- training[inTrain,]</span></p><p class="c3"><span>testData &lt;- training[-inTrain,]</span></p><p class="c2"><span></span></p><p class="c3"><span>This gives us the following data partitions:</span></p><p class="c2"><span></span></p><p class="c3"><span>&gt; dim(trainData)</span></p><p class="c3"><span>[1] 14718    53</span></p><p class="c3"><span>&gt; dim(testData)</span></p><p class="c3"><span>[1] 4904   53</span></p><p class="c2"><span></span></p><h1 class="c3 c4"><a name="h.vw8r8n15qmw"></a><span>Set up parallel/multicore processing</span></h1><p class="c3"><span>Although I ran this on an i7 2.00 GHz 8 core CPU with 16 GB RAM, I had memory allocation issues trying it with more than 4 cores allocated to the processing. Here are the settings I used:</span></p><p class="c2"><span></span></p><p class="c3"><span>cl &lt;- makeCluster(4)</span></p><p class="c3"><span>registerDoParallel(cl)</span></p><h1 class="c3 c4"><a name="h.470uyam877h5"></a><span>Train model using Random Forest</span></h1><p class="c3"><span>I’m using the random forest method as it works well on a large number of variables (we have 52), and there is no need for applying principal component analysis (pca) to reduce the number of predictors, this is implicit in its method, it randomly finds the best fitting predictors. Random forest can lead to overfitting without cross validation. Here we use cross validation with resampling, to produce a low variance but still get good bias.</span></p><p class="c2"><span></span></p><p class="c3"><span>modelFit &lt;- train(classe ~ .,data=trainData,method=&quot;rf&quot;,trControl=trainControl(method=&quot;cv&quot;,number=5,allowParallel=TRUE),prox=TRUE)</span></p><p class="c2"><span></span></p><p class="c3"><span>This produces the model below. You can see that it used the 52 predictors, and found 5 factors in the classe variable, A,B,C,D and E. It also used resampling 5 times with cross-validation.</span></p><p class="c2"><span></span></p><p class="c3"><span>Interestingly enough the final mtry was 2 out of the 52 possible predictors. The plot below (the Model Fit figure) output shows this nicely, with the highest accuracy point being at 2 predictors. I did multiple runs on the training data, this being the last. I notice that sometimes it was not 2, but 27 predictors had the highest accuracy. This shows the variability/randomness in the model training (at least without a seed set).</span></p><p class="c2"><span></span></p><p class="c3"><span>Also the finalModel has 500 trees, although you can see from the plot below (the Final Model figure) that after about 100 trees the error doesn’t change much across all classes.</span></p><p class="c2"><span></span></p><p class="c3"><span>&gt; modelFit</span></p><p class="c3"><span>Random Forest </span></p><p class="c2"><span></span></p><p class="c3"><span>14718 samples</span></p><p class="c3"><span>   52 predictors</span></p><p class="c3"><span>    5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; </span></p><p class="c2"><span></span></p><p class="c3"><span>No pre-processing</span></p><p class="c3"><span>Resampling: Cross-Validated (5 fold) </span></p><p class="c2"><span></span></p><p class="c3"><span>Summary of sample sizes: 11773, 11774, 11774, 11776, 11775 </span></p><p class="c2"><span></span></p><p class="c3"><span>Resampling results across tuning parameters:</span></p><p class="c2"><span></span></p><p class="c3"><span>  mtry  Accuracy   Kappa      Accuracy SD   Kappa SD   </span></p><p class="c3"><span>   2    0.9912352  0.9889115  0.0009117093  0.001153311</span></p><p class="c3"><span>  27    0.9910312  0.9886546  0.0013519706  0.001709911</span></p><p class="c3"><span>  52    0.9835563  0.9791973  0.0051781388  0.006551089</span></p><p class="c2"><span></span></p><p class="c3"><span>Accuracy was used to select the optimal model using  the largest value.</span></p><p class="c3"><span>The final value used for the model was mtry = 2.</span></p><h2 class="c3 c4"><a name="h.o47hamhditmm"></a><span>ModelFit Figure</span></h2><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 480.00px; height: 480.00px;"><img alt="modelFit.png" src="https://lh5.googleusercontent.com/E1B327O3yUBqSg2XWwBmLgYRe-sVc9z2Wwyoaf8N2G33SYcOrddS3cEPyIukllfxibWW16fbj_i3mt-v8PmS3JBH6SjmqUOg8FQq0L0_SfZHTcQaq8TPsjQBTUFI14Z7V4iUWXE" style="width: 480.00px; height: 480.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3"><span>&gt; modelFit$finalModel</span></p><p class="c2"><span></span></p><p class="c3"><span>Call:</span></p><p class="c3"><span> randomForest(x = x, y = y, mtry = param$mtry, proximity = TRUE) </span></p><p class="c3"><span>               Type of random forest: classification</span></p><p class="c3"><span>                     Number of trees: 500</span></p><p class="c3"><span>No. of variables tried at each split: 2</span></p><p class="c2"><span></span></p><p class="c3"><span>        OOB estimate of  error rate: 0.69%</span></p><p class="c3"><span>Confusion matrix:</span></p><p class="c3"><span>     A    B    C    D    E  class.error</span></p><p class="c3"><span>A 4182    2    0    0    1 0.0007168459</span></p><p class="c3"><span>B   19 2822    7    0    0 0.0091292135</span></p><p class="c3"><span>C    0   17 2548    2    0 0.0074016362</span></p><p class="c3"><span>D    0    0   41 2368    3 0.0182421227</span></p><p class="c3"><span>E    0    0    2    7 2697 0.0033259424</span></p><h2 class="c3 c4"><a name="h.z84p93zijnzy"></a><span>Final Model Figure</span></h2><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 480.00px; height: 480.00px;"><img alt="modelFitFinalModel.png" src="https://lh5.googleusercontent.com/ti8543p3V5tXghILWU7hH5g2X1n6aqLJNzIizdBItNRE1JxfxqlrEnPNW9u44zHMHC9V3LKCZZ7xS28XeKU8jLgC3YOkQVlSsbuszgYi5iMXjtekwe9QwjzFZpAbFBQEhtLndBY" style="width: 480.00px; height: 480.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c3 c4"><a name="h.twcmapfaa59x"></a><span>Apply model to the original training set test data (step 3)</span></h1><p class="c3"><span>Applying this to our created test set (not the given test set), we can see how well our model performs. Below from the confusionMatrix you can see that we estimate a high level of accuracy, 99.55%.</span></p><p class="c2"><span></span></p><p class="c3"><span>testPred &lt;- predict(modelFit,newdata=testData)</span></p><p class="c2"><span></span></p><p class="c3"><span>&gt; confusionMatrix(testPred,testData$classe)</span></p><p class="c3"><span>Confusion Matrix and Statistics</span></p><p class="c2"><span></span></p><p class="c3"><span>          Reference</span></p><p class="c3"><span>Prediction    A    B    C    D    E</span></p><p class="c3"><span>         A 1392    3    0    0    0</span></p><p class="c3"><span>         B    1  946    8    0    0</span></p><p class="c3"><span>         C    2    0  847    7    0</span></p><p class="c3"><span>         D    0    0    0  797    1</span></p><p class="c3"><span>         E    0    0    0    0  900</span></p><p class="c2"><span></span></p><p class="c3"><span>Overall Statistics</span></p><p class="c3"><span>                                          </span></p><p class="c3"><span>               Accuracy : 0.9955          </span></p><p class="c3"><span>                 95% CI : (0.9932, 0.9972)</span></p><p class="c3"><span>    No Information Rate : 0.2845          </span></p><p class="c3"><span>    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       </span></p><p class="c3"><span>                                          </span></p><p class="c3"><span>                  Kappa : 0.9943          </span></p><p class="c3"><span> Mcnemar&#39;s Test P-Value : NA              </span></p><p class="c2"><span></span></p><p class="c3"><span>Statistics by Class:</span></p><p class="c2"><span></span></p><p class="c3"><span>                     Class: A Class: B Class: C Class: D Class: E</span></p><p class="c3"><span>Sensitivity            0.9978   0.9968   0.9906   0.9913   0.9989</span></p><p class="c3"><span>Specificity            0.9991   0.9977   0.9978   0.9998   1.0000</span></p><p class="c3"><span>Pos Pred Value         0.9978   0.9906   0.9895   0.9987   1.0000</span></p><p class="c3"><span>Neg Pred Value         0.9991   0.9992   0.9980   0.9983   0.9998</span></p><p class="c3"><span>Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837</span></p><p class="c3"><span>Detection Rate         0.2838   0.1929   0.1727   0.1625   0.1835</span></p><p class="c3"><span>Detection Prevalence   0.2845   0.1947   0.1746   0.1627   0.1835</span></p><p class="c3"><span>Balanced Accuracy      0.9985   0.9973   0.9942   0.9955   0.9994</span></p><h1 class="c3 c4"><a name="h.2kivxenjjiap"></a><span>Estimate Out of Sample Error</span></h1><p class="c3"><span>To verify what the confusionMatrix output is telling us about the estimated accuracy and out of sample error, we calculate the accuracy ourselves, (correct answers/number of rows), then invert that to get the estimate of the Out of Sample Error.</span></p><p class="c2"><span></span></p><p class="c3"><span>&gt; (1 - sum(testPred == testData$classe)/length(testPred)) * 100</span></p><p class="c3"><span>[1] 0.4486134</span></p><p class="c2"><span></span></p><p class="c3"><span>So the estimated Out of Sample Error for the above model is:</span></p><p class="c2"><span></span></p><p class="c3"><span>0.45%</span></p><p class="c2"><span></span></p><p class="c3"><span>which coincides with what the confusionMatrix is telling us i.e. (1 - 0.9955) * 100 = 0.45%</span></p><h1 class="c3 c4"><a name="h.2kl0v8pey9e7"></a><span>Apply model to test data to determine outcomes</span></h1><p class="c3"><span>Now we can apply our model to the given test data, the data we want to determine outcomes for.</span></p><p class="c2"><span></span></p><p class="c3"><span>answers &lt;- predict(modelFit,newdata=testingData)</span></p><p class="c2"><span></span></p><p class="c3"><span>This gives us a list of outcomes for each of the 20 test rows with one value for each test row that is one of A,B,C,D or E.</span></p><h1 class="c3 c4"><a name="h.jlu8cmjbzo3m"></a><span>Write the outcomes to a file for upload and assessment</span></h1><p class="c3"><span>To upload the answers to be assessed, I’m using the code given on the Coursera website:</span></p><p class="c2"><span></span></p><p class="c3"><span>pml_write_files = function(x){<br>  n = length(x)<br>  for(i in 1:n){<br>    filename = paste0(&quot;problem_id_&quot;,i,&quot;.txt&quot;)<br>    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)<br>  }<br>}</span></p><p class="c2"><span></span></p><p class="c3"><span>pml_write_files(answers)</span></p><p class="c2"><span></span></p><p class="c3"><span>This produces 20 files called problem_id_1.txt through problem_id_20.txt, each with one of A,B,C,D or E in them.</span></p></div><div id="footer"><span>Published by <a target="_blank" title="Learn more about Google Drive" href="//docs.google.com/">Google Drive</a></span><span class="dash">&ndash;</span><a href="//docs.google.com/abuse?id=1xe2r7yNhF2EV1xEyZI4dviT6a4GbfJ0RZEttFpyIi3Q">Report Abuse</a><span class="dash">&ndash;</span><span>Updated automatically every 5 minutes</span></div><script type="text/javascript">(function(){if(window.jstiming){window.jstiming.a={};window.jstiming.b=1;var e=function(b,a,d){var c=b.t[a],g=b.t.start;if(c&&(g||d))return c=b.t[a][0],void 0!=d?g=d:g=g[0],Math.round(c-g)},n=function(b,a,d){var c="";window.jstiming.srt&&(c+="&srt="+window.jstiming.srt,delete window.jstiming.srt);window.jstiming.pt&&(c+="&tbsrt="+window.jstiming.pt,delete window.jstiming.pt);try{window.external&&window.external.tran?c+="&tran="+window.external.tran:window.gtbExternal&&window.gtbExternal.tran?c+="&tran="+window.gtbExternal.tran():
window.chrome&&window.chrome.csi&&(c+="&tran="+window.chrome.csi().tran)}catch(g){}var f=window.chrome;if(f&&(f=f.loadTimes)){f().wasFetchedViaSpdy&&(c+="&p=s");if(f().wasNpnNegotiated){var c=c+"&npn=1",k=f().npnNegotiatedProtocol;k&&(c+="&npnv="+(encodeURIComponent||escape)(k))}f().wasAlternateProtocolAvailable&&(c+="&apa=1")}var l=b.t,t=l.start,f=[],k=[],h;for(h in l)if("start"!=h&&0!=h.indexOf("_")){var m=l[h][1];m?l[m]&&k.push(h+"."+e(b,h,l[m][0])):t&&f.push(h+"."+e(b,h))}delete l.start;if(a)for(var p in a)c+=
"&"+p+"="+a[p];(a=d)||(a="https:"==document.location.protocol?"https://csi.gstatic.com/csi":"http://csi.gstatic.com/csi");return[a,"?v=3","&s="+(window.jstiming.sn||"_s")+"&action=",b.name,k.length?"&it="+k.join(","):"",c,"&rt=",f.join(",")].join("")};window.jstiming.getReportUri=n;var q=function(b,a,d){b=n(b,a,d);if(!b)return"";a=new Image;var c=window.jstiming.b++;window.jstiming.a[c]=a;a.onload=a.onerror=function(){window.jstiming&&delete window.jstiming.a[c]};a.src=b;a=null;return b};window.jstiming.report=
function(b,a,d){if("prerender"==document.webkitVisibilityState){var c=!1,g=function(){if(!c){a?a.prerender="1":a={prerender:"1"};var f;"prerender"==document.webkitVisibilityState?f=!1:(q(b,a,d),f=!0);f&&(c=!0,document.removeEventListener("webkitvisibilitychange",g,!1))}};document.addEventListener("webkitvisibilitychange",g,!1);return""}return q(b,a,d)};window.jstiming.reportDone=function(b){if(window.jstiming.b<=(b||1))return!1;for(var a in window.jstiming.a)return!1;return!0};var r=function(b,a,
d,c){return 0<d?(c?b.tick(a,c,d):b.tick(a,"",d),!0):!1};window.jstiming.getNavTiming=function(b){if(window.performance&&window.performance.timing){var a=window.performance.timing;r(b,"_dns",a.domainLookupStart)&&r(b,"dns_",a.domainLookupEnd,"_dns");r(b,"_con",a.connectStart)&&r(b,"con_",a.connectEnd,"_con");r(b,"_req",a.requestStart)&&r(b,"req_",a.responseStart,"_req");r(b,"_rcv",a.responseStart)&&r(b,"rcv_",a.responseEnd,"_rcv");if(r(b,"_ns",a.navigationStart)){r(b,"ntsrt_",a.responseStart,"_ns");
r(b,"nsfs_",a.fetchStart,"_ns");var d=window.external&&window.external.startE;!d&&window.chrome&&window.chrome.csi&&(d=Math.floor(window.chrome.csi().startE));d&&(r(b,"_se",d),r(b,"sens_",a.navigationStart,"_se"));r(b,"ntplt0_",a.loadEventStart,"_ns");r(b,"ntplt1_",a.loadEventEnd,"_ns")}}}};})()
</script>
<script type="text/javascript">KX_timer.tick('tl'); if (document.location.protocol == 'https:') {window.jstiming.report(KX_timer, undefined , 'https://gg.google.com/csi');} else {window.jstiming.report(KX_timer);}</script></body></html>
